0. Выяснить, насколько хорошо отобрали пары документ-категория: какой процент единичек из всей матрицы покрыли этим множеством?
1. Продумать алгоритм близкий по своему смыслу к тому, что видели в описании на форуме kaggle, 
	но с параметрами, которые можно варьировать

	
	подбирать параметры для категорий (локальный подсчет метрики на сайте)
	
	
	Ќайти величину - аналог энтропии в baseline.
	Ќа каком-то примере пар категории-документа, проверить, правильно ли считаетсЯ энтропиЯ, выЯснить, что может быть неправильно
	Џочему алгоритм baseline лучше энтропии?
	Џочему максимальной энтропии не соответствует документ, принадлежащий категории? ЌаходитсЯ ли эта пара алгоритмом из baseline?
	Ќайти несколько примеров пар документ-категориЯ с большой энтропией, но которые не соответствуют друг другу 
	
	entr = 0.657973, doc = 2127362, categ = 29745, in train =0
	entr = 0.631078, doc = 704096, categ = 245246, in train =0
	entr = 0.623891, doc = 921327, categ = 245246, in train =0
	entr = 0.584163, doc = 887888, categ = 245246, in train =0
	entr = 0.580181, doc = 976754, categ = 344539, in train =0
	
30.09.2015	
метрика близости у нас не очень, 
нужен - быстро считающийсЯ эксперимент, демонстрирующий качество метрик

14.10.2015
исправить ошибки и добитьсЯ того же значениЯ, что и baseline
если вдруг получитсЯ сразу, то записать вместо энтропии количество общих категорий и протестировать
 на том методе подбора наилучшего количества категорий
 
 11.11.2015
 1) на исходном множестве запустить knn (без исправлений) и отправить на сайте
 2) если в пункте 1 получитсЯ то, что есть на сайте, отправить baseline по отобранным с помощью энтропии парам документ-категориЯ
 
icpc -std=c++11 -openmp -O2 kaggle.cpp -g1 -traceback -o kaggle


на трейне - 0.13
чистый алгоритм - 0.17952
с модификацией отбрасываниЯ уникальных терминов - 0.18040

25.11.2015
1) Џредсказание по энтропии с выбором наилучшего количества предсказываемых документов длЯ категории отправить на kaggle, должно получитьсЯ 0.26 
(ну или во всЯком случае 0.2078 - как получилось в трейн множестве)
2) если получитсЯ первый пункт, то как сделать еще лучше? например, скрестить энтропию с тф-идф, кнн
вспомнить, как считали энтропию. Ќадо не стрелЯть, тратЯ патроны, а попробовать прицелитьсЯ. Ќесколько вариантов, как можно использовать и почему они могут быть лучше в комбинации
Џо какому принципу отобраны категории длЯ теста?
3) сделать функцию подсчета энтропии с параметрами


что показывает энтропия? - выш 0.09577 подняться почему-то не удается
возможные проблемы: 1) неправильное чтение - но оно же используется и в том, что дает 0.18040   - потестить чтение тестового файла, сравнить функции - НЕТ, ОНО ПРАВИЛЬНОЕ
					2) ошибка в алгоритме построения тестового множества  - еще раз проверить досконально  - НЕ ОТЛИЧАЕТСЯ ОТ ПОСТРОЕНИЯ ТРЕЙНА
					3) результат 0,2078 недостижим, т.к. для него использовалось заглядывание в будущее и мб какие-то другие причины  - что делать???
					
					
дз
0. все в git

09.12.2015
провели классный эксперимент.
 на kaggle плохие результаты, т.к. переобучение. Построили график MaF(барьер), и он жутко изрезан, причём резкие обрывы наблюдаются только с левой стороны. Нужно стараться брать лучшее 
 значение барьера чуть больше, чем оно есть на одной выборке. 
 Правильный выход из создавшегося ужасного положения: 

Проводим серию вычисл экспериментов. 

после подбора размера категорий результат 0.09274 - почему?
0.10231 - после исправлений

18.02.2015 
1) попробовать итерационный процесс начинать с различных начальных точек
2) сделать для нескольких категорий файл, в которых были бы 0-1 для всех проведенных экспериментов {[эксперимент-внутри через запятую тоже], [эксперимент]}
{[0,1,1,0],[1,0,0],...}

т1. рассмотрим случайный эксперимент: делим данные (статистику) на две части: обучающую и проверочную случайным образом.
 рассмотрим случайную величину: MaF, вычисленный для некоторого алгоритма предсказания, заданного фиксированной функцией упорядочивания пар документ-категория и неизвестной функцией выбора барьеров для каждой категории. 
 Доказать, что среднее значение MaF максимально ттт когда набор барьеров является многомерной точкой максимума функции MAF, 
 которая получается из случайной величины, если вместо дробей написать их мат ожидания

т2. дано: обучающая выборка, метрика качества macro f1-score, функция, упорядочивающая пары категория-документ (энтропия).
задан итерационный метод, определяющий на каждой итерации наилучшее значение барьера для каждой категории
(в нашем алгоритме на каждой итерации каждое следующее значение барьера выбирается с учетом уже подобранных предыдущих значений, но, вообще говоря,
 можно скопировать всю выборку и подбирать только на основе старого множества - возможно, так удастся доказать)
 
 доказать: 1) для любого начального приближения наш итерационный  метод сходится к какому-то пределу. 
 2) предел не зависит от выбора начального приближения (и выбора итерационного алгоритма - см. замечание в скобках выше)

 где-то надо добавить предельный переход к бесконечному числу категорий
 посмотреть на что обобщается (другие macro f-score)